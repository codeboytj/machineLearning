{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeboytj/machineLearning/blob/master/src/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWytHBA0nrX-",
        "colab_type": "text"
      },
      "source": [
        "$y = w^TX+b$\n",
        "\n",
        "$cost(w, b) = \\sum_{i=1}^m (w^Tx_i+b-y_i)^2$\n",
        "\n",
        "$\\frac{\\partial cost}{\\partial w} = \\sum_{i=1}^m 2x_i(w^Tx_i+b-y_i)$\n",
        "\n",
        "$\\frac{\\partial cost}{\\partial b} = \\sum_{i=1}^m 2(w^Tx_i+b-y_i)$\n",
        "\n",
        "learning rate = $\\alpha$\n",
        "\n",
        "algorithmï¼š\n",
        "\n",
        "1. initalize $w$,$b$ and $\\alpha$\n",
        "\n",
        "2. calculate cost by $w$,$b$\n",
        "\n",
        "3. update $w$,$b$ and $\\alpha$ by:\n",
        "$w = w - \\alpha\\frac{\\partial cost}{\\partial w}$\n",
        ",$b = b - \\alpha\\frac{\\partial cost}{\\partial b}$\n",
        "\n",
        "4. calculate the new cost by $w$,$b$ and $\\alpha$\n",
        "\n",
        "5. check if the difference of the new cost and the last cost is lower than a threshold. If so, we get the final $w$,$b$. else, we need to back to step 3 again and continue the loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhO2JMGXhMKr",
        "colab_type": "code",
        "outputId": "b1bea22c-a669-4542-8d4d-e4c966dcef26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr49KuXkx_ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGycmcLSnJn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearModel(object):\n",
        "  def __init__(self):\n",
        "    self.W = tf.Variable(np.array([5.,6.]))\n",
        "    self.b = tf.Variable(np.array([1.]))\n",
        "  def __call__(self, x):\n",
        "    return tf.multiply(self.W,x) + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x51SxJKz0xWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(true_y, predicted_y):\n",
        "  return tf.reduce_mean(tf.square(true_y-predicted_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW_vl0C912ZC",
        "colab_type": "code",
        "outputId": "222e0639-9b32-41eb-da48-4db4eada5cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "model = LinearModel()\n",
        "\n",
        "x = tf.constant(np.random.rand(100,2))\n",
        "y = tf.constant(np.array([2.,3.]))*x + tf.constant(np.array([3.]))\n",
        "\n",
        "def train():\n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(y, model(x))\n",
        "  dW,db = t.gradient(current_loss, [model.W, model.b])\n",
        "  model.W.assign_sub(0.1 * dW)\n",
        "  model.b.assign_sub(0.1 * db)\n",
        "  \n",
        "for i in range(1000):\n",
        "  train()\n",
        "  \n",
        "print(loss(y, model(x)))\n",
        "print(model.W.numpy())\n",
        "print(model.b.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.225787005401851e-07, shape=(), dtype=float64)\n",
            "[2.00199466 3.00192385]\n",
            "[2.99894434]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}